{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect, Column, Integer, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import sqlite3\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV Files\n",
    "\n",
    "# sources: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results/data#\n",
    "# Data starts in 1896\n",
    "events_file = 'Resources/athlete_events.csv'\n",
    "df_events_orig = pd.read_csv(events_file)\n",
    "\n",
    "# source: World Bank (https://databank.worldbank.org/reports.aspx?source=2&series=NY.GDP.MKTP.CD&country=#) \n",
    "# Data starts in 1960\n",
    "pop_gdp_file = 'Resources/population_gdp.csv'\n",
    "df_pop_gdp_orig = pd.read_csv(pop_gdp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Clean Worldbank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 - rename columns\n",
    "df_pop_gdp = df_pop_gdp_orig\n",
    "df_pop_gdp = df_pop_gdp.drop(columns = ['Series Code'], axis =1)\n",
    "df_pop_gdp = df_pop_gdp.rename(\n",
    "    columns={\n",
    "        \"Series Name\": \"Series\", \n",
    "        \"Country Name\": \"Country\",\n",
    "        \"Country Code\": \"NOC\"})\n",
    "\n",
    "df_pop_gdp.columns = df_pop_gdp.columns.str.split(' ').str[0].tolist()\n",
    "\n",
    "keep_columns = ['Series', 'Country', 'NOC']\n",
    "event_years = df_events_orig.Year.unique().astype(str)\n",
    "\n",
    "for i in event_years:\n",
    "    keep_columns.append(i)\n",
    "\n",
    "df_pop_gdp = df_pop_gdp[df_pop_gdp.columns.intersection(keep_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - filter by GDP and Population series_names\n",
    "df_pop_gdp_1 = df_pop_gdp.loc[(df_pop_gdp[\"Series\"] == \"GDP (current US$)\") | (df_pop_gdp[\"Series\"] == \"Population, total\")]\n",
    "df_pop_gdp_2 = df_pop_gdp_1.melt(id_vars=['Series', 'Country', 'NOC'])\n",
    "df_pop_gdp_2 = df_pop_gdp_2.rename(columns={'variable':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - Reformat the table\n",
    "df_pop_gdp_final = df_pop_gdp_2.pivot_table(index=['Year','NOC','Country'], values = 'value', columns='Series', aggfunc='sum')\n",
    "df_pop_gdp_final = df_pop_gdp_final.reset_index()\n",
    "df_pop_gdp_final = df_pop_gdp_final.rename(columns = {'GDP (current US$)': 'GDP', 'Population, total': 'Population'})\n",
    "df_pop_gdp_final['Population'] = np.where(df_pop_gdp_final['Population'] == '..', 0, df_pop_gdp_final['Population'])\n",
    "df_pop_gdp_final['GDP'] = np.where(df_pop_gdp_final['GDP'] == '..', 0, df_pop_gdp_final['GDP'])\n",
    "df_pop_gdp_final = df_pop_gdp_final.astype({'GDP': 'float64', 'Year': 'int64', 'Population': 'int64'})\n",
    "df_pop_gdp_final['GDP_per_capita'] = df_pop_gdp_final['GDP'] / df_pop_gdp_final['Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Clean Olympic Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 1 - define df_events dataframe\n",
    "df_events = df_events_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - clean NOC (in df_events) based on worldbank NOC to match each other\n",
    "\n",
    "# extract WorldBank's NOC (Country code) and Country (name)\n",
    "df_worldbanknames = pd.DataFrame(df_pop_gdp_final.groupby(['NOC','Country']).size().reset_index())\n",
    "df_worldbanknames = df_worldbanknames.drop(columns=[0])\n",
    "\n",
    "# create a column with stripped country_name and sanitize\n",
    "df_worldbanknames['Wclean'] = df_worldbanknames ['Country'].str.replace(\" \", \"\").str.lower()\n",
    "\n",
    "# create a column with stripped Team name in Olympic Data and sanitize\n",
    "df_events['Oclean'] = df_events ['Team'].str.replace(\" \", \"\").str.lower()\n",
    "\n",
    "# Unique transformations of countries that are in both data bases, but didn't match up.\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"IRI\", \"IRN\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"GER\", \"DEU\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"BAH\", \"BHS\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"SUI\", \"CHE\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"ISV\", \"VIR\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"GRE\", \"GRC\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"DEN\", \"DNK\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"NED\", \"NLD\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"CGO\", \"COG\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"LAT\", \"LVA\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"INA\", \"IDN\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"GAM\", \"GMB\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"GBS\", \"GNB\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"MAS\", \"MYS\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"NGR\", \"NGA\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"VIN\", \"VCT\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"BRU\", \"BRN\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"SLO\", \"SVN\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"MRI\", \"MUS\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"BUL\", \"BGR\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"PUR\", \"PRI\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"MON\", \"MCO\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"SKN\", \"KNA\")\n",
    "df_events['NOC'] = df_events['NOC'].str.replace(\"POR\", \"PRT\")\n",
    "\n",
    "# merge by stripped country names and make sure Olympic Data NOC matches WorldBank country_code\n",
    "df_events = pd.merge(df_events, df_worldbanknames, how=\"left\", left_on='Oclean', right_on = 'Wclean', suffixes=('', '_y'))\n",
    "df_events['NOC'] = np.where(df_events['NOC_y'].isnull(), df_events['NOC'], df_events['NOC_y'])\n",
    "\n",
    "# drop unncessary columns from the merge\n",
    "df_events = df_events.drop(columns = ['Oclean', 'NOC_y', 'Wclean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  step 3 - clean Country names based on the NOC (for small teams with Country NOCs)\n",
    "df_events = pd.merge(df_events, df_worldbanknames, how=\"left\", left_on='NOC', right_on = 'NOC', suffixes=('', '_y'))\n",
    "df_events['Country'] = np.where(df_events['Country'].isnull(), df_events['Country_y'], df_events['Country'])\n",
    "# drop unncessary columns from the merge\n",
    "df_events = df_events.drop(columns = ['Country_y', 'Wclean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  step 4 - clean Country names that do not match with World Bank, but have medals \n",
    "df_events_not_matching = pd.merge(df_events, df_worldbanknames, how = \"left\", left_on = ['NOC'], right_on = ['NOC'], suffixes=('', '_y'))\n",
    "not_matching_NOC = df_events_not_matching[df_events_not_matching['Country_y'].isnull()]\n",
    "not_matching_NOC = not_matching_NOC.groupby(['NOC','Team']).count().reset_index()\n",
    "not_matching_NOC = not_matching_NOC.drop(columns = ['ID', 'Name', 'Sex', 'Age', 'Height', 'Weight',\n",
    "       'Games', 'Year', 'Season', 'City', 'Sport', 'Event', 'Country', 'Country_y', 'Wclean'], axis =1)\n",
    "\n",
    "not_matching_NOC = not_matching_NOC[not_matching_NOC['Medal'] > 0]\n",
    "max_medals_NOC = not_matching_NOC.groupby(['NOC'])['Medal'].transform(max) == not_matching_NOC['Medal']\n",
    "max_medals_NOC = not_matching_NOC[max_medals_NOC]\n",
    "\n",
    "df_events = pd.merge(df_events, max_medals_NOC, how=\"left\", left_on='NOC', right_on = 'NOC', suffixes=('', '_y'))\n",
    "df_events['Country'] = np.where(df_events['Country'].isnull(), df_events['Team_y'], df_events['Country'])\n",
    "# drop unncessary columns from the merge\n",
    "df_events = df_events.drop(columns = ['Team_y', 'Medal_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - use Team name when Country name is NaN\n",
    "df_events['Country'] = np.where(df_events['Country'].isnull(), df_events['Team'], df_events['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6 - filter Olympic games database to be only after 1960\n",
    "df_events = df_events[df_events[\"Year\"] >= 1960]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Classes for the needed sqlite tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Events(Base):\n",
    "    __tablename__ = 'events'\n",
    "    ID = Column(Integer, primary_key=True)\n",
    "    Name = Column(String(255))\n",
    "    Sex = Column(String(255))\n",
    "    Age = Column(Integer)\n",
    "    Height = Column(Integer)\n",
    "    Weight = Column(Integer)\n",
    "    Team = Column(String(255))\n",
    "    NOC = Column(String(255))\n",
    "    Games = Column(String(255))\n",
    "    Year = Column(Integer, primary_key=True)\n",
    "    Season = Column(String(255))\n",
    "    City = Column(String(255))\n",
    "    Sport = Column(String(255))\n",
    "    Event = Column(String(255), primary_key=True)\n",
    "    Medal = Column(String(255))\n",
    "    Country = Column(String(255), primary_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Events_Final(Base):\n",
    "    __tablename__ = 'events_final'\n",
    "    Year = Column(Integer, primary_key=True)\n",
    "    Season = Column(String(255), primary_key=True)\n",
    "    City = Column(String(255), primary_key=True)\n",
    "    NOC = Column(String(255), primary_key=True)\n",
    "    Country = Column(String(255), primary_key=True)\n",
    "    Game_Label = Column(String(255))\n",
    "    Chart_Label = Column(String(255))\n",
    "    GDP = Column(Float)\n",
    "    Population = Column(Integer)\n",
    "    GDP_per_capita = Column(Float)\n",
    "    No_olympians = Column(Integer)\n",
    "    Bronze_athlete = Column(Integer)\n",
    "    Gold_athlete = Column(Integer)\n",
    "    Silver_athlete = Column(Integer)\n",
    "    Total_Medals_athlete = Column(Integer)\n",
    "    Bronze_team = Column(Integer)\n",
    "    Gold_team = Column(Integer)\n",
    "    Silver_team = Column(Integer)\n",
    "    Total_Medals_team = Column(Integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create SQLite database and connect to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Create engine connection, classes, session and connection\n",
    "disk_engine = create_engine('sqlite:///olympic_events.sqlite')\n",
    "Base.metadata.create_all(disk_engine)\n",
    "session = Session(disk_engine)\n",
    "conn = disk_engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Upload events dataframe into SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Export the df_events dataframe to sqlite\n",
    "df_events.to_sql('events', disk_engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prepare the code for Events Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base table\n",
    "events_country = pd.read_sql_query('SELECT year, season, city, NOC, country FROM events \\\n",
    "GROUP BY year, season, city, NOC, country',disk_engine)\n",
    "events_country['Game_Label'] = events_country['Season'] + ' ' + events_country['Year'].map(str) + ' - '  + events_country['City'] \n",
    "events_country['Chart_Label'] = events_country['Year'].map(str) + ' - '  + events_country['City'] \n",
    "events_country = events_country[['Year', 'Season', 'City', 'Game_Label', 'NOC', 'Chart_Label', 'Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Athletes\n",
    "# Step 1 Intermediate table\n",
    "olympians_team_detail = pd.read_sql_query('SELECT year, season, name, NOC FROM events \\\n",
    "GROUP BY year, season, name, NOC',disk_engine)\n",
    "olympians_team = olympians_team_detail.groupby(['Year','Season', 'NOC']).count()\n",
    "olympians_team.reset_index(inplace = True)\n",
    "olympians_team = olympians_team.rename(columns = {\"Name\": \"No_olympians\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Medals per athlete\n",
    "# Step 1\n",
    "medals_athlete_detail = pd.read_sql_query('SELECT year, season, NOC, sport, event, name, sex, medal FROM events \\\n",
    "GROUP BY year, season, NOC, sport, event, name, sex, medal',disk_engine)\n",
    "# Step 2\n",
    "medals_athlete = medals_athlete_detail.groupby(['Year','Season','NOC', 'Name','Medal']).count()[['Sport']]\n",
    "medals_athlete.reset_index(inplace = True)\n",
    "medals_athlete.rename(columns = {\"Sport\": \"#Medals\"}, inplace = True)\n",
    "medals_athlete.sort_values(by=[\"#Medals\"], ascending=False)\n",
    "# Step 3\n",
    "medals_athlete_pivot = medals_athlete.pivot_table(index=['Year','Season','NOC','Name'], values = '#Medals', columns='Medal', aggfunc='sum')\n",
    "medals_athlete_pivot.reset_index(inplace = True)\n",
    "medals_athlete_pivot.replace(np.nan,0, inplace = True)\n",
    "\n",
    "# Step 4\n",
    "medals_athlete_pivot['Gold_athlete'] = np.where(medals_athlete_pivot['Gold'] > 0, 1, 0)\n",
    "medals_athlete_pivot['Silver_athlete'] = np.where((medals_athlete_pivot['Gold_athlete'] == 0) & (medals_athlete_pivot['Silver'] > 0), 1, 0)\n",
    "medals_athlete_pivot['Bronze_athlete'] = np.where((medals_athlete_pivot['Gold_athlete'] == 0) & (medals_athlete_pivot['Silver_athlete'] == 0), 1, 0)\n",
    "medals_athlete_pivot[\"Total_Medals_athlete\"] = medals_athlete_pivot[\"Bronze_athlete\"] + medals_athlete_pivot[\"Gold_athlete\"] + medals_athlete_pivot[\"Silver_athlete\"]\n",
    "\n",
    "medals_athlete_total = medals_athlete_pivot.groupby(['Year','Season','NOC']).sum()[['Silver_athlete','Bronze_athlete','Gold_athlete','Total_Medals_athlete']]\n",
    "medals_athlete_total.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Medals per sport\n",
    "# Step 1\n",
    "medals_sport_detail = pd.read_sql_query('SELECT year, season, NOC, sport, event, sex, medal FROM events \\\n",
    "GROUP BY year, season, NOC, sport, event, sex, medal',disk_engine)\n",
    "# Step 2\n",
    "medals_sport = medals_sport_detail.groupby(['Year','Season','NOC', 'Medal']).count()[['Event']]\n",
    "medals_sport.reset_index(inplace = True)\n",
    "medals_sport.rename(columns = {\"Event\": \"#Medals\"}, inplace = True)\n",
    "medals_sport.sort_values(by=[\"#Medals\"], ascending=False)\n",
    "# Step 3\n",
    "medals_sport_total = medals_sport.pivot_table(index=['Year','Season','NOC'], values = '#Medals', columns='Medal', aggfunc='sum')\n",
    "medals_sport_total.reset_index(inplace = True)\n",
    "medals_sport_total.replace(np.nan,0, inplace = True)\n",
    "medals_sport_total = medals_sport_total.rename(columns = {\"Bronze\": \"Bronze_team\", \"Gold\":\"Gold_team\", \"Silver\": \"Silver_team\"})\n",
    "medals_sport_total[\"Total_Medals_team\"] = medals_sport_total[\"Bronze_team\"] + medals_sport_total[\"Gold_team\"] + medals_sport_total[\"Silver_team\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final data gathering to reach Events_final\n",
    "\n",
    "# step 1 - merging tables\n",
    "events_merge_1 = pd.merge(events_country, df_pop_gdp_final, how = \"left\", left_on = ['Year','NOC'], right_on = ['Year','NOC'], suffixes=('', '_y'))\n",
    "events_merge_1 = events_merge_1.drop(columns = ['Country_y'])\n",
    "events_merge_2 = pd.merge(events_merge_1, olympians_team, how = \"left\", left_on = ['Year','Season', 'NOC'], right_on = ['Year','Season', 'NOC'])\n",
    "events_merge_3 = pd.merge(events_merge_2, medals_athlete_total, how = \"left\", left_on = ['Year','Season', 'NOC'], right_on = ['Year','Season', 'NOC'])\n",
    "events_merge_4 = pd.merge(events_merge_3, medals_sport_total, how = \"left\", left_on = ['Year','Season', 'NOC'], right_on = ['Year','Season', 'NOC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - prepare aggregated value for all countries - World (WLD)\n",
    "wld_events_1 = events_merge_4.groupby(['Year','Season','City','Game_Label', 'Chart_Label']).sum()\n",
    "wld_events_2 = pd.DataFrame(wld_events_1).reset_index()\n",
    "wld_events_2['NOC'] = 'WLD'\n",
    "wld_events_2['Country'] = 'World'\n",
    "\n",
    "# add the WLD Pop and GDP information\n",
    "wld_base_info = df_pop_gdp_final[df_pop_gdp_final['NOC'] == 'WLD']\n",
    "wld_all_info = pd.merge(wld_events_2, wld_base_info, how = \"left\", left_on = ['NOC','Year','Country'], right_on = ['NOC','Year','Country'], suffixes=('_x', ''))\n",
    "wld_all_info = wld_all_info.drop(columns = ['GDP_x', 'Population_x', 'GDP_per_capita_x'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - add aggregated value for all countries - World (WLD) in Events_Final\n",
    "events_pre_final = pd.concat([events_merge_4, wld_all_info], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 4 - drop countries not recognized by World Bank and without medals over the years\n",
    "merge_wld_bank = pd.merge(events_pre_final, df_worldbanknames, how = \"left\", left_on = ['NOC'], right_on = ['NOC'], suffixes=('', '_y'))\n",
    "\n",
    "# NOCs not matching World Bank\n",
    "not_matching_NOC = merge_wld_bank[merge_wld_bank['Country_y'].isnull()]\n",
    "not_matching_NOC = not_matching_NOC.groupby(['NOC','Country']).sum().reset_index()\n",
    "not_matching_NOC = not_matching_NOC.drop(columns = ['Year', 'GDP', 'Population', 'GDP_per_capita',\n",
    "       'No_olympians', 'Bronze_athlete', 'Gold_athlete', 'Silver_athlete',\n",
    "       'Total_Medals_athlete', 'Bronze_team', 'Gold_team', 'Silver_team'], axis =1)\n",
    "\n",
    "# drop rows with columns not maching world bank and without medals\n",
    "not_matching_NOC_no_medals = not_matching_NOC[not_matching_NOC['Total_Medals_team'] == 0]\n",
    "not_matching_NOC_no_medals = not_matching_NOC_no_medals.groupby('NOC').all().reset_index()\n",
    "not_matching_NOC_no_medals = not_matching_NOC_no_medals.drop(columns = ['Total_Medals_team'])\n",
    "\n",
    "events_pre_final = pd.merge(events_pre_final, not_matching_NOC_no_medals, how = \"left\", left_on = ['NOC'], right_on = ['NOC'], suffixes=('', '_Drop'))\n",
    "indexNames = events_pre_final[events_pre_final['Country_Drop'] == True].index\n",
    "events_pre_final.drop(indexNames , inplace=True)\n",
    "events_pre_final = events_pre_final.drop(columns = ['Country_Drop'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - create events_final\n",
    "events_final = events_pre_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Events Final Table into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6 - load the events_final in SQLite\n",
    "events_final.to_sql('events_final', disk_engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Events Final Table into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7 - load the events_final into JSON file for choropleth map\n",
    "events_final.to_json('medal_counts.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
